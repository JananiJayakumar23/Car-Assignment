# -*- coding: utf-8 -*-
"""Car assessment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UmQGBX98Eseg6db_7CxZ1UaGCBehoyel
"""

!git clone https://github.com/JananiJayakumar23/Car-Assignment.git

!pip install geopandas

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import colors as c
from matplotlib import gridspec as grid
from sklearn.metrics import RocCurveDisplay

df1=pd.read_csv('/content/Car-Assignment/Car_Assignment1.csv')
df2=pd.read_csv('/content/Car-Assignment/Car_Assignment 2 .csv')
df3=pd.read_csv('/content/Car-Assignment/Car_Assignment 3.csv')

#print the first five entries of the dataset
df1.head()

#print the rows and columns of dataset1
df1.shape

df1.info()

#check the dtype of dataset 1
df1.dtypes

#print the value count of all columns in dataset1
for i in df1:
    print(i,':\n',len(df1[i].value_counts()),'modalities')

#count the number of missing values in dataset1
df1.isna().sum()

df1.isna().values.any()

# drop the missing values
df1.dropna(inplace=True)

df1.isna().sum()

df1.describe().T

# Distribution of numerical features
num_cols = df1.select_dtypes(include=np.number).columns
for col in num_cols:
    plt.figure(figsize=(6,4))
    sns.histplot(df1[col], kde=True, bins=30)
    plt.title(f"Distribution of {col}")
    plt.show()

# Countplots for categorical features
cat_cols = df1.select_dtypes(include="object").columns
for col in cat_cols:
    plt.figure(figsize=(6,4))
    sns.countplot(data=df1, x=col, order=df1[col].value_counts().index)
    plt.xticks(rotation=45)
    plt.title(f"Countplot of {col}")
    plt.show()

plt.figure(figsize=(10,6))
sns.heatmap(df1[num_cols].corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_squared_error, r2_score, classification_report, confusion_matrix, roc_auc_score, silhouette_score

from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

df_encoded = pd.get_dummies(df1, drop_first=True)

#Predict price (Regression)
X = df_encoded.drop(columns=['price', 'Successful_Model'])
y = df_encoded['price']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Scale
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Question 1 Price Prediction
# Linear Regression
lin_reg = LinearRegression()
lin_reg.fit(X_train_scaled, y_train)
y_pred = lin_reg.predict(X_test_scaled)
print("Price Prediction")
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))
print("RÂ²:", r2_score(y_test, y_pred))

#Question 2
#Binary Classification (Successful Model)
X_cls = df_encoded.drop(columns=['Successful_Model'])
y_cls = df_encoded['Successful_Model']

X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_cls, y_cls, test_size=0.3, random_state=42)

# Logistic Regression
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train_c, y_train_c)
y_pred_lr = log_reg.predict(X_test_c)

print("Logistic Regression")
print(classification_report(y_test_c, y_pred_lr))
print("ROC-AUC:", roc_auc_score(y_test_c, log_reg.predict_proba(X_test_c)[:,1]))

# Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train_c, y_train_c)
y_pred_rf = rf.predict(X_test_c)

print(" Random Forest")
print(classification_report(y_test_c, y_pred_rf))
print("ROC-AUC:", roc_auc_score(y_test_c, rf.predict_proba(X_test_c)[:,1]))

# SVM
svm = SVC(probability=True)
svm.fit(X_train_c, y_train_c)
y_pred_svm = svm.predict(X_test_c)

print("SVM")
print(classification_report(y_test_c, y_pred_svm))
print("ROC-AUC:", roc_auc_score(y_test_c, svm.predict_proba(X_test_c)[:,1]))

# Q3: Clustering
features = ['horsepower', 'price', 'citympg', 'highwaympg']
X_cluster = df1[features].copy()

# Scale
X_scaled = StandardScaler().fit_transform(X_cluster)

# Find optimal k using Silhouette Score
sil_scores = []
for k in range(2, 8):
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X_scaled)
    sil = silhouette_score(X_scaled, labels)
    sil_scores.append((k, sil))

# Choose best k
best_k = max(sil_scores, key=lambda x: x[1])[0]
print(" Clustering")
print("Best k by silhouette score:", best_k)

# Final KMeans
kmeans = KMeans(n_clusters=best_k, random_state=42)
clusters = kmeans.fit_predict(X_scaled)
df1['Cluster'] = clusters

# Cluster visualization (PCA 2D)
pca = PCA(n_components=2)
pca_coords = pca.fit_transform(X_scaled)
plt.figure(figsize=(8,6))
sns.scatterplot(x=pca_coords[:,0], y=pca_coords[:,1], hue=clusters, palette="Set2")
plt.title("Car Clusters (PCA Projection)")
plt.show()

# Cluster Summary
print(df1.groupby('Cluster')[['horsepower','price','citympg','highwaympg']].mean())

import matplotlib.pyplot as plt
from statsmodels.tsa.statespace.sarimax import SARIMAX
from prophet import Prophet
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error

# Questin 4
# Load Car_Assignment2
df2['Date'] = pd.to_datetime(df2['Date'])
df2 = df2.groupby('Date')['Sales'].sum().reset_index()

# Resample weekly sales
df2 = df2.set_index('Date').resample('W').sum().reset_index()

# Train-test split (last 12 weeks for validation)
train = df2[:-12]
test = df2[:-12]

#Model 1: SARIMA
sarima_model = SARIMAX(train['Sales'], order=(1,1,1), seasonal_order=(1,1,1,52))
sarima_fit = sarima_model.fit(disp=False)
sarima_forecast = sarima_fit.forecast(steps=len(test))
# match test size

# Model 2: Prophet
prophet_df = train.rename(columns={'Date':'ds','Sales':'y'})
prophet_model = Prophet()
prophet_model.fit(prophet_df)
future = prophet_model.make_future_dataframe(periods=len(test), freq='W')
prophet_forecast = prophet_model.predict(future).tail(len(test))['yhat']

# --- Evaluate ---
sarima_rmse = np.sqrt(mean_squared_error(test['Sales'], sarima_forecast))
prophet_rmse = np.sqrt(mean_squared_error(test['Sales'], prophet_forecast))

print("Forecast Evaluation")
print("SARIMA RMSE:", sarima_rmse)
print("Prophet RMSE:", prophet_rmse)

#Q5: Relationship between Price, Ad Spend, and Sales (Car_Assignment3)
import statsmodels.api as sm

# Correlation check
print("Correlation Matrix")
print(df3[['Sales','Price','Ad Spend']].corr())

# Multiple Regression
X = df3[['Price','Ad Spend']]
y = df3['Sales']

X = sm.add_constant(X)  # add intercept
model = sm.OLS(y, X).fit()
print(model.summary())